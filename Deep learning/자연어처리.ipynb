{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "abcf8b9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['나라의 말이 중국과 달라 ',\n",
       " '한자와는 서로 통하지 아니하여서 ',\n",
       " '이런 까닭으로 어리석은 백성이 ',\n",
       " '말하고자 하는 바가 있어도 ',\n",
       " '마침내 제 뜻을 능히 펴지',\n",
       " '못하는 사람이 많다',\n",
       " '내가 이를 위하여 가엾게 여겨 ',\n",
       " '새로 스물여덟 자를 만드니',\n",
       " '사람마다 하여금 쉽게 익혀 날마다 씀에 ',\n",
       " '편안케 하고자 할 따름이다']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "texts=\"\"\"나라의 말이 중국과 달라 \n",
    "한자와는 서로 통하지 아니하여서 \n",
    "이런 까닭으로 어리석은 백성이 \n",
    "말하고자 하는 바가 있어도 \n",
    "마침내 제 뜻을 능히 펴지\n",
    "못하는 사람이 많다\n",
    "내가 이를 위하여 가엾게 여겨 \n",
    "새로 스물여덟 자를 만드니\n",
    "사람마다 하여금 쉽게 익혀 날마다 씀에 \n",
    "편안케 하고자 할 따름이다\"\"\"\n",
    "texts=texts.split('\\n')\n",
    "display(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9255e8a3",
   "metadata": {},
   "source": [
    "# 음절단위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e8b2a0e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'편｜안｜케｜ ｜하｜고｜자｜ ｜할｜ ｜따｜름｜이｜다'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[' ', '가', '게', '겨', '고', '과', '국', '금', '까', '나']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens = []\n",
    "tokenized_texts = []\n",
    "for text in texts : \n",
    "    tokenized_text = text\n",
    "    for token in tokenized_text : \n",
    "        tokens.append(token)\n",
    "    tokenized_text = \"｜\".join(tokenized_text) \n",
    "    tokenized_texts.append(tokenized_text)\n",
    "tokens = list(set(tokens)) \n",
    "tokens = sorted(list(tokens))\n",
    "display(tokenized_text) \n",
    "display(tokens[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e4d47a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(' ', 0),\n",
       " ('가', 1),\n",
       " ('게', 2),\n",
       " ('겨', 3),\n",
       " ('고', 4),\n",
       " ('과', 5),\n",
       " ('국', 6),\n",
       " ('금', 7),\n",
       " ('까', 8),\n",
       " ('나', 9)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(0, ' '),\n",
       " (1, '가'),\n",
       " (2, '게'),\n",
       " (3, '겨'),\n",
       " (4, '고'),\n",
       " (5, '과'),\n",
       " (6, '국'),\n",
       " (7, '금'),\n",
       " (8, '까'),\n",
       " (9, '나')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "token_to_index = dict((token, index) for index, token in enumerate(tokens)) \n",
    "index_to_token = dict((index, token) for token, index in token_to_index.items())\n",
    "display(list(token_to_index.items())[:10]) \n",
    "display(list(index_to_token.items())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da0def2f",
   "metadata": {},
   "source": [
    "# 단어단위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "95490ae2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['나｜라｜의｜ ｜말｜이｜ ｜중｜국｜과｜ ｜달｜라｜ ',\n",
       " '한｜자｜와｜는｜ ｜서｜로｜ ｜통｜하｜지｜ ｜아｜니｜하｜여｜서｜ ',\n",
       " '이｜런｜ ｜까｜닭｜으｜로｜ ｜어｜리｜석｜은｜ ｜백｜성｜이｜ ',\n",
       " '말｜하｜고｜자｜ ｜하｜는｜ ｜바｜가｜ ｜있｜어｜도｜ ',\n",
       " '마｜침｜내｜ ｜제｜ ｜뜻｜을｜ ｜능｜히｜ ｜펴｜지',\n",
       " '못｜하｜는｜ ｜사｜람｜이｜ ｜많｜다',\n",
       " '내｜가｜ ｜이｜를｜ ｜위｜하｜여｜ ｜가｜엾｜게｜ ｜여｜겨｜ ',\n",
       " '새｜로｜ ｜스｜물｜여｜덟｜ ｜자｜를｜ ｜만｜드｜니',\n",
       " '사｜람｜마｜다｜ ｜하｜여｜금｜ ｜쉽｜게｜ ｜익｜혀｜ ｜날｜마｜다｜ ｜씀｜에｜ ',\n",
       " '편｜안｜케｜ ｜하｜고｜자｜ ｜할｜ ｜따｜름｜이｜다',\n",
       " '나라의｜말이｜중국과｜달라',\n",
       " '한자와는｜서로｜통하지｜아니하여서',\n",
       " '이런｜까닭으로｜어리석은｜백성이',\n",
       " '말하고자｜하는｜바가｜있어도',\n",
       " '마침내｜제｜뜻을｜능히｜펴지',\n",
       " '못하는｜사람이｜많다',\n",
       " '내가｜이를｜위하여｜가엾게｜여겨',\n",
       " '새로｜스물여덟｜자를｜만드니',\n",
       " '사람마다｜하여금｜쉽게｜익혀｜날마다｜씀에',\n",
       " '편안케｜하고자｜할｜따름이다']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['가엾게', '까닭으로', '나라의', '날마다', '내가', '능히', '달라', '따름이다', '뜻을', '마침내']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenw = []\n",
    "Tokenized_texts = []\n",
    "for text in texts :\n",
    "    tokenized_text = text.split() \n",
    "    for token in tokenized_text :\n",
    "        tokenw.append(token)\n",
    "    tokenized_text = \"｜\".join(tokenized_text) \n",
    "    tokenized_texts.append(tokenized_text)\n",
    "tokenw = list(set(tokenw)) \n",
    "tokenw = sorted(list(tokenw))\n",
    "display(tokenized_texts) \n",
    "display(tokenw[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "30dd3457",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('가엾게', 0),\n",
       " ('까닭으로', 1),\n",
       " ('나라의', 2),\n",
       " ('날마다', 3),\n",
       " ('내가', 4),\n",
       " ('능히', 5),\n",
       " ('달라', 6),\n",
       " ('따름이다', 7),\n",
       " ('뜻을', 8),\n",
       " ('마침내', 9)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(0, '가엾게'),\n",
       " (1, '까닭으로'),\n",
       " (2, '나라의'),\n",
       " (3, '날마다'),\n",
       " (4, '내가'),\n",
       " (5, '능히'),\n",
       " (6, '달라'),\n",
       " (7, '따름이다'),\n",
       " (8, '뜻을'),\n",
       " (9, '마침내')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens_to_index = dict((token1, index) for index, token1 in enumerate(tokenw)) \n",
    "index_to_token = dict((index, token1) for token1, index in tokens_to_index.items())\n",
    "display(list(tokens_to_index.items())[:10]) \n",
    "display(list(index_to_token.items())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e93c116",
   "metadata": {},
   "source": [
    "# 형태소단위"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b7ca6165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\users\\yimst\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\yimst\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\yimst\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\yimst\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\yimst\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\yimst\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\yimst\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\yimst\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\yimst\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\yimst\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\yimst\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\yimst\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\yimst\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\yimst\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\yimst\\appdata\\roaming\\python\\python39\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-gpu (c:\\users\\yimst\\appdata\\roaming\\python\\python39\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collecting konlpy\n",
      "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
      "     --------------------------------------- 19.4/19.4 MB 50.4 MB/s eta 0:00:00\n",
      "Collecting JPype1>=0.7.0\n",
      "  Downloading JPype1-1.4.1-cp39-cp39-win_amd64.whl (345 kB)\n",
      "     ---------------------------------------- 345.2/345.2 kB ? eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from konlpy) (1.21.5)\n",
      "Requirement already satisfied: lxml>=4.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from konlpy) (4.9.1)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from JPype1>=0.7.0->konlpy) (21.3)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from packaging->JPype1>=0.7.0->konlpy) (3.0.9)\n",
      "Installing collected packages: JPype1, konlpy\n",
      "Successfully installed JPype1-1.4.1 konlpy-0.6.0\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "5cb0957b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Okt\n",
    "tokenizer = Okt()\n",
    "tokens = []\n",
    "tokenizeds_text = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "af12c5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for text in texts :\n",
    "    tokenized_text = tokenizer.morphs(text) \n",
    "    for token in tokenized_text :\n",
    "        tokens.append(token)        \n",
    "    tokenized_text = \"｜\".join(tokenized_text) \n",
    "    tokenizeds_text.append(tokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "7bd85ac1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['가', '가엾게', '과', '까닭', '나라', '날', '내', '능', '달라', '따름']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[('가', 0),\n",
       " ('가엾게', 1),\n",
       " ('과', 2),\n",
       " ('까닭', 3),\n",
       " ('나라', 4),\n",
       " ('날', 5),\n",
       " ('내', 6),\n",
       " ('능', 7),\n",
       " ('달라', 8),\n",
       " ('따름', 9)]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(0, '가'),\n",
       " (1, '가엾게'),\n",
       " (2, '과'),\n",
       " (3, '까닭'),\n",
       " (4, '나라'),\n",
       " (5, '날'),\n",
       " (6, '내'),\n",
       " (7, '능'),\n",
       " (8, '달라'),\n",
       " (9, '따름')]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokens = list(set(tokens))\n",
    "tokens = sorted(list(tokens)) \n",
    "\n",
    "display(tokens[:10])\n",
    "\n",
    "tokens_to_index =dict((token1, index) for index, token1 in enumerate(tokens)) \n",
    "display(list(tokens_to_index.items())[:10])\n",
    "index_to_token = dict((index, token1) for token1, index in tokens_to_index.items())\n",
    "display(list(index_to_token.items())[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616e69a9",
   "metadata": {},
   "source": [
    "# 피처벡터화\n",
    "## 원핫인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "98a65e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'한글': 0, '딥러닝': 1, '케라스': 2, '세종대왕': 3, '광화문': 4, '자연어처리': 5}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "한글\t[1. 0. 0. 0. 0. 0.]\n",
      "딥러닝\t[0. 1. 0. 0. 0. 0.]\n",
      "케라스\t[0. 0. 1. 0. 0. 0.]\n",
      "세종대왕\t[0. 0. 0. 1. 0. 0.]\n",
      "광화문\t[0. 0. 0. 0. 1. 0.]\n",
      "자연어처리\t[0. 0. 0. 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "tokens = ['한글', '딥러닝','케라스','세종대왕','광화문','자연어처리'] \n",
    "token_to_index = dict((token,index) for index, token in enumerate(tokens))\n",
    "display(token_to_index) \n",
    "import numpy as np\n",
    "for token in tokens :\n",
    "    token_onehot = np.zeros((len(tokens)), dtype = 'float32') \n",
    "    token_onehot[token_to_index[token]] = 1\n",
    "    print(token + '\\t' + str(token_onehot))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
