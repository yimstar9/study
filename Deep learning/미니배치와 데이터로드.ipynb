{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5203957",
   "metadata": {},
   "source": [
    "# 1. 미니 배치와 배치 크기(Mini Batch and Batch Size)\n",
    "https://wikidocs.net/55580"
   ]
  },
  {
   "cell_type": "raw",
   "id": "64fbb0d6",
   "metadata": {},
   "source": [
    "에포크(Epoch)는 전체 훈련 데이터가 학습에 한 번 사용된 주기를 말한다고 언급한 바 있습니다.\n",
    "미니 배치 학습에서는 미니 배치의 개수만큼 경사 하강법을 수행해야 전체 데이터가 한 번 전부 사용되어 1 에포크(Epoch)가 됩니다. 미니 배치의 개수는 결국 미니 배치의 크기를 몇으로 하느냐에 따라서 달라지는데 미니 배치의 크기를 배치 크기(batch size)라고 합니다.\n",
    "\n",
    "전체 데이터에 대해서 한 번에 경사 하강법을 수행하는 방법을 '배치 경사 하강법'이라고 부릅니다. 반면, 미니 배치 단위로 경사 하강법을 수행하는 방법을 '미니 배치 경사 하강법'이라고 부릅니다.\n",
    "\n",
    "배치 경사 하강법은 경사 하강법을 할 때, 전체 데이터를 사용하므로 가중치 값이 최적값에 수렴하는 과정이 매우 안정적이지만, 계산량이 너무 많이 듭니다. 미니 배치 경사 하강법은 경사 하강법을 할 때, 전체 데이터의 일부만을 보고 수행하므로 최적값으로 수렴하는 과정에서 값이 조금 헤매기도 하지만 훈련 속도가 빠릅니다.\n",
    "\n",
    "배치 크기는 보통 2의 제곱수를 사용합니다. ex) 2, 4, 8, 16, 32, 64... 그 이유는 CPU와 GPU의 메모리가 2의 배수이므로 배치크기가 2의 제곱수일 경우에 데이터 송수신의 효율을 높일 수 있다고 합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea5fe2f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d5f9167",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset # 텐서데이터셋\n",
    "from torch.utils.data import DataLoader # 데이터로더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc9f0bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train  =  torch.FloatTensor([[73,  80,  75], \n",
    "                               [93,  88,  93], \n",
    "                               [89,  91,  90], \n",
    "                               [96,  98,  100],   \n",
    "                               [73,  66,  70]])  \n",
    "y_train  =  torch.FloatTensor([[152],  [185],  [180],  [196],  [142]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c8e1e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "924150b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c44c2ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(3,1)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98bf3ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/20 Batch 1/3 Cost: 29098.359375\n",
      "Epoch    0/20 Batch 2/3 Cost: 3955.958984\n",
      "Epoch    0/20 Batch 3/3 Cost: 3135.041260\n",
      "Epoch    1/20 Batch 1/3 Cost: 535.478516\n",
      "Epoch    1/20 Batch 2/3 Cost: 222.782654\n",
      "Epoch    1/20 Batch 3/3 Cost: 65.072083\n",
      "Epoch    2/20 Batch 1/3 Cost: 20.980616\n",
      "Epoch    2/20 Batch 2/3 Cost: 1.595148\n",
      "Epoch    2/20 Batch 3/3 Cost: 14.976744\n",
      "Epoch    3/20 Batch 1/3 Cost: 6.305820\n",
      "Epoch    3/20 Batch 2/3 Cost: 3.214480\n",
      "Epoch    3/20 Batch 3/3 Cost: 3.523125\n",
      "Epoch    4/20 Batch 1/3 Cost: 6.112226\n",
      "Epoch    4/20 Batch 2/3 Cost: 4.057210\n",
      "Epoch    4/20 Batch 3/3 Cost: 2.885633\n",
      "Epoch    5/20 Batch 1/3 Cost: 4.916459\n",
      "Epoch    5/20 Batch 2/3 Cost: 4.022911\n",
      "Epoch    5/20 Batch 3/3 Cost: 6.344886\n",
      "Epoch    6/20 Batch 1/3 Cost: 0.244013\n",
      "Epoch    6/20 Batch 2/3 Cost: 11.281515\n",
      "Epoch    6/20 Batch 3/3 Cost: 7.744776\n",
      "Epoch    7/20 Batch 1/3 Cost: 0.383845\n",
      "Epoch    7/20 Batch 2/3 Cost: 10.685520\n",
      "Epoch    7/20 Batch 3/3 Cost: 8.002435\n",
      "Epoch    8/20 Batch 1/3 Cost: 4.847536\n",
      "Epoch    8/20 Batch 2/3 Cost: 6.232590\n",
      "Epoch    8/20 Batch 3/3 Cost: 0.444716\n",
      "Epoch    9/20 Batch 1/3 Cost: 0.658455\n",
      "Epoch    9/20 Batch 2/3 Cost: 6.359463\n",
      "Epoch    9/20 Batch 3/3 Cost: 8.301197\n",
      "Epoch   10/20 Batch 1/3 Cost: 3.359440\n",
      "Epoch   10/20 Batch 2/3 Cost: 11.270902\n",
      "Epoch   10/20 Batch 3/3 Cost: 0.589574\n",
      "Epoch   11/20 Batch 1/3 Cost: 3.777043\n",
      "Epoch   11/20 Batch 2/3 Cost: 4.728740\n",
      "Epoch   11/20 Batch 3/3 Cost: 10.091597\n",
      "Epoch   12/20 Batch 1/3 Cost: 6.306243\n",
      "Epoch   12/20 Batch 2/3 Cost: 2.297159\n",
      "Epoch   12/20 Batch 3/3 Cost: 7.641003\n",
      "Epoch   13/20 Batch 1/3 Cost: 4.625744\n",
      "Epoch   13/20 Batch 2/3 Cost: 6.678180\n",
      "Epoch   13/20 Batch 3/3 Cost: 10.198421\n",
      "Epoch   14/20 Batch 1/3 Cost: 7.591869\n",
      "Epoch   14/20 Batch 2/3 Cost: 7.657164\n",
      "Epoch   14/20 Batch 3/3 Cost: 0.130768\n",
      "Epoch   15/20 Batch 1/3 Cost: 2.295483\n",
      "Epoch   15/20 Batch 2/3 Cost: 6.269812\n",
      "Epoch   15/20 Batch 3/3 Cost: 7.327770\n",
      "Epoch   16/20 Batch 1/3 Cost: 4.716725\n",
      "Epoch   16/20 Batch 2/3 Cost: 6.138275\n",
      "Epoch   16/20 Batch 3/3 Cost: 5.778296\n",
      "Epoch   17/20 Batch 1/3 Cost: 4.209752\n",
      "Epoch   17/20 Batch 2/3 Cost: 3.233033\n",
      "Epoch   17/20 Batch 3/3 Cost: 8.768506\n",
      "Epoch   18/20 Batch 1/3 Cost: 4.008071\n",
      "Epoch   18/20 Batch 2/3 Cost: 6.113280\n",
      "Epoch   18/20 Batch 3/3 Cost: 2.680996\n",
      "Epoch   19/20 Batch 1/3 Cost: 1.557493\n",
      "Epoch   19/20 Batch 2/3 Cost: 5.851461\n",
      "Epoch   19/20 Batch 3/3 Cost: 8.062893\n",
      "Epoch   20/20 Batch 1/3 Cost: 4.593422\n",
      "Epoch   20/20 Batch 2/3 Cost: 2.445047\n",
      "Epoch   20/20 Batch 3/3 Cost: 8.301109\n"
     ]
    }
   ],
   "source": [
    "nb_epochs = 20\n",
    "for epoch in range(nb_epochs + 1):\n",
    "  for batch_idx, samples in enumerate(dataloader):\n",
    "    # print(batch_idx)\n",
    "    # print(samples)\n",
    "    x_train, y_train = samples\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.mse_loss(prediction, y_train)\n",
    "\n",
    "    # cost로 H(x) 계산\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print('Epoch {:4d}/{} Batch {}/{} Cost: {:.6f}'.format(\n",
    "        epoch, nb_epochs, batch_idx+1, len(dataloader),\n",
    "        cost.item()\n",
    "        ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d7c2f617",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 후 입력이 73, 80, 75일 때의 예측값 : tensor([[153.8811]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# 임의의 입력 [73, 80, 75]를 선언\n",
    "new_var =  torch.FloatTensor([[73, 80, 75]]) \n",
    "# 입력한 값 [73, 80, 75]에 대해서 예측값 y를 리턴받아서 pred_y에 저장\n",
    "pred_y = model(new_var) \n",
    "print(\"훈련 후 입력이 73, 80, 75일 때의 예측값 :\", pred_y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7046cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
